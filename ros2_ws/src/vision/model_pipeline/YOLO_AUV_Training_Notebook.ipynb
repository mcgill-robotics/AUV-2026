{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edX5GkTFMdS0"
   },
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1758598142375,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "Z1PBpdg0MdS4"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "is_front_camera_training = False  # Change it to False if training for down cmaera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1758598142385,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "89yJH2cyMdS5"
   },
   "outputs": [],
   "source": [
    "################################# OS PARAMETERS ##################################\n",
    "os_name = os.name\n",
    "# Windows = nt, [Linux, Apple] = posix.\n",
    "os_path = \"\\\\\" if os_name == \"nt\" else \"/\"\n",
    "##################################################################################\n",
    "############################## ROBOFLOW  PARAMETERS ##############################\n",
    "roboflow_api_key = \"u7zfMxAWzFvZlg4S2QTH\"    # \"MJQUATZvpcKoBxRjLuXx\"\n",
    "roboflow_workspace_name = \"robosub-2025-mu9e7\"\n",
    "dataset_export_format = \"yolov8\"\n",
    "# if is_front_camera_training:\n",
    "#     roboflow_project_name = \"down-camera-comp\"\n",
    "# else:\n",
    "#     roboflow_project_name = \"down-camera-sim\"\n",
    "roboflow_project_name = \"douglas-vision-model\"\n",
    "##################################################################################\n",
    "############################## TRAINING  PARAMETERS ##############################\n",
    "# if is_front_camera_training:\n",
    "#     target_classes = [\"bouy\", \"gate\", \"octagon-table\"]\n",
    "#     model_save_filename = \"best_AUV_sim_front_camera_model.pt\"\n",
    "# else:\n",
    "#     target_classes = [\"bin\", \"lane-marker\", \"octagon-table\"]\n",
    "#     model_save_filename = \"best_AUV_sim_down_camera_model.pt\"\n",
    "target_classes = [\"gate\", \"octagon table\", \"octagon top\", \"path_marker\", \"sawfish\", \"shark\"]\n",
    "model_name = \"yolov8n.pt\"\n",
    "train_test_val_split = (0.7, 0.2, 0.1)\n",
    "epoch_increments = 200\n",
    "batch_size = -1 # Auto Mode (60% GPU Memory): Use batch=-1 to automatically\n",
    "                # adjust batch size for approximately 60% CUDA memory\n",
    "                # utilization.\n",
    "workers = 2\n",
    "cache = False\n",
    "pretrained = True\n",
    "imgsz = [480, 640]\n",
    "hsv_h = 0.015\n",
    "hsv_s = 0.3\n",
    "hsv_v = 0.3\n",
    "translate = 0.0\n",
    "scale = 0.0\n",
    "fliplr = 0.5\n",
    "flipud = 0.5\n",
    "mosaic = 0.1\n",
    "copy_paste = 0.0\n",
    "erasing = 0.0\n",
    "crop_fraction = 0.1\n",
    "degrees = 180\n",
    "##################################################################################\n",
    "######################### CUSTOM AUGMENTATION PARAMETERS #########################\n",
    "colorAugmentProb = 0.5\n",
    "noiseAugmentProb = 0.5\n",
    "resolutionAugmentProb = 0.0\n",
    "contrastAugmentProb = 0.5\n",
    "blurAugmentProb = 0.5\n",
    "brightnessAugmentProb = 0.5\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASKXCqQmMdS6"
   },
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYnA3UlpMdS6"
   },
   "source": [
    "## Setup python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26776,
     "status": "ok",
     "timestamp": 1758598169162,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "WvqrCspBMdS6",
    "outputId": "22faed83-4e47-4e84-fe72-8685dbabe09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.jetson-ai-lab.io/jp6/cu126\n",
      "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.2.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in /usr/lib/python3/dist-packages (from roboflow) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from roboflow) (1.3.2)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from roboflow) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (11.3.0)\n",
      "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.5.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/lib/python3/dist-packages (from roboflow) (5.4.1)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
      "Looking in indexes: https://pypi.jetson-ai-lab.io/jp6/cu126\n",
      "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.12.0)\n",
      "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.24->albumentations) (4.2.0)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.1)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Looking in indexes: https://pypi.jetson-ai-lab.io/jp6/cu126\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Packages installed successfully.\n"
     ]
    }
   ],
   "source": [
    "packages = [\n",
    "     \"roboflow\",\n",
    "     \"albumentations\",\n",
    "     \"pandas\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    for package in packages:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    print(\"Packages installed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10408,
     "status": "ok",
     "timestamp": 1758598179575,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "PrqUeH7gMdS7",
    "outputId": "5dc4c6e4-52d8-4550-c6d8-91202db49edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from roboflow import Roboflow\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1811,
     "status": "ok",
     "timestamp": 1758598181392,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "vjuS08lRMdS7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜dataâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmentedâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/imagesâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/labelsâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/trainâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/testâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/valâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/train/imagesâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/test/imagesâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/val/imagesâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/train/labelsâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/test/labelsâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/augmented/val/labelsâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/rawâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/raw/imagesâ€™: File exists\n",
      "mkdir: cannot create directory â€˜data/raw/labelsâ€™: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!mkdir data/augmented\n",
    "!mkdir data/augmented/images\n",
    "!mkdir data/augmented/labels\n",
    "!mkdir data/augmented/train\n",
    "!mkdir data/augmented/test\n",
    "!mkdir data/augmented/val\n",
    "!mkdir data/augmented/train/images\n",
    "!mkdir data/augmented/test/images\n",
    "!mkdir data/augmented/val/images\n",
    "!mkdir data/augmented/train/labels\n",
    "!mkdir data/augmented/test/labels\n",
    "!mkdir data/augmented/val/labels\n",
    "!mkdir data/raw\n",
    "!mkdir data/raw/images\n",
    "!mkdir data/raw/labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjPTIx8ZMdS7"
   },
   "source": [
    "## Define YOLO classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1758598181423,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "cEYERzI4MdS7",
    "outputId": "19736497-8724-40bd-c4db-03fe028e8775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data absolute path: /root/AUV-2026/ros2_ws/src/vision/model_pipeline/data.\n"
     ]
    }
   ],
   "source": [
    "data_folder_absolute_path = os.path.abspath(\"data\")\n",
    "print(f\"Data absolute path: {data_folder_absolute_path}.\")\n",
    "\n",
    "with open(\"data.yaml\", \"w+\") as f:\n",
    "    f.write(f\"train: {data_folder_absolute_path}{os_path}augmented{os_path}train{os_path}images\\n\")\n",
    "    f.write(f\"test: {data_folder_absolute_path}{os_path}augmented{os_path}test{os_path}images\\n\")\n",
    "    f.write(f\"val: {data_folder_absolute_path}{os_path}augmented{os_path}val{os_path}images\\n\")\n",
    "    f.write(f\"nc: {len(target_classes)}\\n\")\n",
    "    f.write(f\"names: {target_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPIjYbG8MdS8"
   },
   "source": [
    "## Define augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1758598181436,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "zMt18ugyMdS8"
   },
   "outputs": [],
   "source": [
    "# Given a list of samples, make two copies of each sample that are darker/brighter to simulate differently lit environments.\n",
    "def brightnessAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.ColorJitter(brightness=(1.5, 1.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        bright_img = transform(image=image)[\"image\"]\n",
    "        transform = A.Compose([A.ColorJitter(brightness=(0.5, 0.5), contrast=0, saturation=0, hue=0, always_apply=True)])\n",
    "        dark_img = transform(image=image)[\"image\"]\n",
    "        out.append(bright_img)\n",
    "        out.append(dark_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but more blurred to simulate objects out of focus, dirty lenses, and backscattering.\n",
    "def blurAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        ksize = (8, 8) # lower to lower blur\n",
    "        blurred_img = cv2.blur(image, ksize)\n",
    "        out.append(blurred_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with a lower contrast image to simulate backscattering and over/under-exposure.\n",
    "def contrastAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.ColorJitter (brightness=0, contrast=(0.5, 0.5), saturation=0, hue=0, always_apply=True)])\n",
    "        decontrasted_img = transform(image=image)[\"image\"]\n",
    "        out.append(decontrasted_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with camera noise added to the image to simulate different camera feeds.\n",
    "def noiseAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.ISONoise(color_shift=(0.1, 0.1), intensity=(0.5, 0.5), always_apply=True)])\n",
    "        noisy_img = transform(image=image)[\"image\"]\n",
    "        out.append(noisy_img)\n",
    "    return out\n",
    "\n",
    "# Given a list of samples, make a copy of each sample but with the image downscaled (lower resolution of image) to simulate lower quality cameras/images.\n",
    "def resolutionAugment(images):\n",
    "    out = []\n",
    "    for image in images:\n",
    "        transform = A.Compose([A.Downscale(scale_min=0.2, scale_max=0.2, always_apply=True)])\n",
    "        low_res_img = transform(image=image)[\"image\"]\n",
    "        out.append(low_res_img)\n",
    "    return out\n",
    "\n",
    "# Increase intensity of blues in given image.\n",
    "def make_bluer(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_b = np.uint16(img_b)\n",
    "    img_b += color_shift_intensity\n",
    "    np.clip(img_b, 0, 255, out=img_b)\n",
    "    img_b = np.uint8(img_b)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Increase intensity of greens in given image.\n",
    "def make_greener(img, color_shift_intensity):\n",
    "    img_b, img_g, img_r = cv2.split(img) # Split by channel.\n",
    "    img_g = np.uint16(img_g)\n",
    "    img_g += color_shift_intensity\n",
    "    np.clip(img_g, 0, 255, out=img_g)\n",
    "    img_g = np.uint8(img_g)\n",
    "    img = cv2.merge((img_b, img_g, img_r)) # Merge adjusted channels.\n",
    "    del img_b\n",
    "    del img_g\n",
    "    del img_r\n",
    "    return img\n",
    "\n",
    "# Given a list of samples, make two copies of each sample (one bluer, one greener) to simulate different pools + color attenuation.\n",
    "def colorAugment(images):\n",
    "    out = []\n",
    "    color_shift_intensity = int(255*0.05)\n",
    "    for image in images:\n",
    "        blue_img = make_bluer(image, color_shift_intensity)\n",
    "        green_img = make_greener(image, color_shift_intensity)\n",
    "        out.append(blue_img)\n",
    "        out.append(green_img)\n",
    "    return out\n",
    "\n",
    "# Given a single image and augmentation function, displays the image before and images after augmentation.\n",
    "def visualizeAugmentation(img, aug):\n",
    "    # Show original image.\n",
    "    cv2.imshow(\"og\", img)\n",
    "    cv2.waitKey(0)\n",
    "    # Show all augmented images.\n",
    "    for augmented in aug([(img, \"\")])[1:]:\n",
    "        cv2.imshow(\"augmented\", augmented[0])\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1758598181483,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "6PPILubGMdS8"
   },
   "outputs": [],
   "source": [
    "def get_file_names(source_folder):\n",
    "    label_filenames = []\n",
    "    img_filenames = [f for f in os.listdir(source_folder + f\"{os_path}images\") if os.path.isfile(os.path.join(source_folder + f\"{os_path}images\", f))]\n",
    "    for img_filename in img_filenames:\n",
    "        label_filenames.append(os.path.splitext(img_filename)[0] + \".txt\")\n",
    "\n",
    "    return np.array(img_filenames), np.array(label_filenames)\n",
    "\n",
    "def split_and_move_data(source_dir, dest_dir, split_ratio=(0.7, 0.2, 0.1)):\n",
    "    source_image_dir = f\"{source_dir}{os_path}images\"\n",
    "    source_label_dir = f\"{source_dir}{os_path}labels\"\n",
    "    # Get list of image and label files.\n",
    "    image_files = sorted(os.listdir(source_image_dir))\n",
    "    label_files = sorted(os.listdir(source_label_dir))\n",
    "\n",
    "    # Shuffle the indices.\n",
    "    indices = np.arange(len(image_files))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Calculate split indices.\n",
    "    total_count = len(image_files)\n",
    "    train_end = int(total_count * split_ratio[0])\n",
    "    val_end = train_end + int(total_count * split_ratio[1])\n",
    "\n",
    "    train_indices = indices[:train_end]\n",
    "    val_indices = indices[train_end:val_end]\n",
    "    test_indices = indices[val_end:]\n",
    "\n",
    "    # Function to move files\n",
    "    def move_files(indices, split):\n",
    "        for i in indices:\n",
    "            shutil.move(os.path.join(source_image_dir, image_files[i]),\n",
    "                        os.path.join(dest_dir, split, 'images', image_files[i]))\n",
    "            shutil.move(os.path.join(source_label_dir, label_files[i]),\n",
    "                        os.path.join(dest_dir, split, 'labels', label_files[i]))\n",
    "\n",
    "    # Move files to corresponding folders\n",
    "    move_files(train_indices, 'train')\n",
    "    move_files(val_indices, 'val')\n",
    "    move_files(test_indices, 'test')\n",
    "\n",
    "def get_augs(img_filename, source_folder):\n",
    "    img = cv2.imread(source_folder + f\"{os_path}images{os_path}\" + img_filename)\n",
    "    augs = [img]\n",
    "    if(np.random.rand() < colorAugmentProb):\n",
    "        augs = augs + colorAugment(augs)\n",
    "    if(np.random.rand() < noiseAugmentProb):\n",
    "        augs = augs + noiseAugment(augs)\n",
    "    if(np.random.rand() < resolutionAugmentProb):\n",
    "        augs = augs + resolutionAugment(augs)\n",
    "    if(np.random.rand() < contrastAugmentProb):\n",
    "        augs = augs + contrastAugment(augs)\n",
    "    if(np.random.rand() < blurAugmentProb):\n",
    "        augs = augs + blurAugment(augs)\n",
    "    if(np.random.rand() < brightnessAugmentProb):\n",
    "        augs = augs + brightnessAugment(augs)\n",
    "    return augs\n",
    "\n",
    "def do_augs_and_export(img_filenames, label_filenames, source_folder, output_folder):\n",
    "    name_num = 1\n",
    "    for (img_filename, label_filename) in zip(img_filenames, label_filenames):\n",
    "        augs = get_augs(img_filename, source_folder)\n",
    "        with open(source_folder + f\"{os_path}labels{os_path}\" + label_filename) as f:\n",
    "            #build array of bounding boxes (each line its own element)\n",
    "            bounding_boxes = f.read()\n",
    "        for aug in augs:\n",
    "            cv2.imwrite(output_folder + f\"{os_path}images{os_path}img\" + str(name_num) + \".png\", aug)\n",
    "            with open(output_folder + f\"{os_path}labels{os_path}img\" + str(name_num) + \".txt\", \"w+\") as f:\n",
    "                f.write(bounding_boxes)\n",
    "            name_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lzGbLXwMdS9"
   },
   "source": [
    "## Download dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1758598184960,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "hwvnNBIzMdS9",
    "outputId": "7c50402d-6822-4017-f20e-caec1dcfa403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Exporting format yolov8 in progress : 85.0%\n",
      "Version export complete for yolov8 format\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Douglas-Vision-Model-7 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87458/87458 [00:07<00:00, 11691.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Douglas-Vision-Model-7 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1890/1890 [00:00<00:00, 2122.94it/s]\n"
     ]
    }
   ],
   "source": [
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.workspace(roboflow_workspace_name).project(roboflow_project_name)\n",
    "latest_version = int(project.versions()[0].version)\n",
    "version = project.version(latest_version)\n",
    "dataset = version.download(dataset_export_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1758598185033,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "NdBHUz_1MdS9",
    "outputId": "67cf9209-1cad-4457-a711-400697ba58a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roboflow folder name: Douglas-Vision-Model-7.\n",
      "Moving train folder...\n",
      "Moving train folder completed.\n",
      "Moving valid folder...\n",
      "Moving valid folder completed.\n",
      "Moving test folder...\n",
      "Moving test folder completed.\n",
      "Removed folder: Douglas-Vision-Model-7.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"Douglas-Vision-Model-7\"# \"{}-{}\".format(roboflow_project_name, latest_version)\n",
    "roboflow_folder_path = os.path.abspath(folder_name)\n",
    "data_folder_path = os.path.abspath(\"data\")\n",
    "\n",
    "print(f\"Roboflow folder name: {folder_name}.\")\n",
    "\n",
    "def copy_all_files(source, destination):\n",
    "     try:\n",
    "          # Ensure destination folder exists.\n",
    "          os.makedirs(destination, exist_ok=True)\n",
    "          # Copy all files from source to destination.\n",
    "          for filename in os.listdir(source):\n",
    "               source_file = os.path.join(source, filename)\n",
    "               if os.path.isfile(source_file):\n",
    "                    destination_file = os.path.join(destination, filename)\n",
    "                    shutil.move(source_file, destination_file)\n",
    "     except Exception as e:\n",
    "          print(f\"Error copying files: {e}.\")\n",
    "\n",
    "# Copy files from roboflow to data folder.\n",
    "for folder in [\"train\", \"valid\", \"test\"]:\n",
    "     print(f\"Moving {folder} folder...\")\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"images\"),\n",
    "                    os.path.join(data_folder_path, \"raw\", \"images\"))\n",
    "     copy_all_files(os.path.join(roboflow_folder_path, folder, \"labels\"),\n",
    "                    os.path.join(data_folder_path, \"raw\", \"labels\"))\n",
    "     print(f\"Moving {folder} folder completed.\")\n",
    "\n",
    "# Optional: Remove roboflow folder after copying files.\n",
    "try:\n",
    "     shutil.rmtree(folder_name)\n",
    "     print(f\"Removed folder: {folder_name}.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error removing folder: {e}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmqJF8yGMdS-"
   },
   "source": [
    "## Augment data, split into train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 74098,
     "status": "ok",
     "timestamp": 1758598259160,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "5Mu7ywZpMdS-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "out_folder = f\"data{os_path}augmented\"\n",
    "in_folder = f\"data{os_path}raw\"\n",
    "train = f\"{os_path}train\"\n",
    "val = f\"{os_path}val\"\n",
    "test = f\"{os_path}test\"\n",
    "\n",
    "raw_image_names, raw_label_names = get_file_names(in_folder)\n",
    "num_raw_samples = len(raw_image_names)\n",
    "do_augs_and_export(raw_image_names, raw_label_names, in_folder, out_folder)\n",
    "split_and_move_data(out_folder, out_folder)\n",
    "\n",
    "os.rmdir(f\"data{os_path}augmented{os_path}images\")\n",
    "os.rmdir(f\"data{os_path}augmented{os_path}labels\")\n",
    "shutil.rmtree(in_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1758598259188,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "cXCkrrEWMdS-",
    "outputId": "638bea4f-ab0d-41d2-e344-87f36a1415d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed: went from 939 samples to 12651 after augmentation.\n"
     ]
    }
   ],
   "source": [
    "augmented_train_img_names, _ = get_file_names(out_folder + train)\n",
    "augmented_test_img_names, _ = get_file_names(out_folder + test)\n",
    "augmented_val_img_names, _ = get_file_names(out_folder + val)\n",
    "\n",
    "num_augmented_samples = len(augmented_train_img_names) + len(augmented_test_img_names) + len(augmented_val_img_names)\n",
    "\n",
    "print(f\"Augmentation completed: went from {num_raw_samples} samples to {num_augmented_samples} after augmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ciR_xKCMdS-"
   },
   "source": [
    "# Check CUDA dependencies and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1758598259237,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "Be5VCLOGMdS-"
   },
   "outputs": [],
   "source": [
    "if not (torch.cuda.is_available() and torch.cuda.device_count()):\n",
    "    raise RuntimeError(\"CUDA is NOT available. Please ensure that your system has a compatible GPU and the necessary drivers are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1758598259299,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "EDPEbr99MdS_"
   },
   "outputs": [],
   "source": [
    "runs_folder = \"runs\"\n",
    "detect_folder = \"detect\"\n",
    "\n",
    "if os.path.exists(runs_folder):\n",
    "    shutil.rmtree(runs_folder)\n",
    "\n",
    "os.makedirs(os.path.join(runs_folder, detect_folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1758598259347,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "C2BsY2GuMdS_"
   },
   "outputs": [],
   "source": [
    "# callback method tracks losses on the training and validation data after each fit epoch (train + val) to test model convergence and fit\n",
    "\n",
    "# bounding box loss: This loss component measures how accurately the model predicts the spatial location and size of bounding boxes around detected objects.\n",
    "# classification loss: This loss component evaluates the model's ability to correctly classify the objects within the predicted bounding boxes.\n",
    "# distribution focal loss: This loss component assesses the model's robustness to class imbalances\n",
    "train_box_losses, train_cls_losses, train_dfl_losses = [], [], []\n",
    "val_box_losses, val_cls_losses, val_dfl_losses = [], [], []\n",
    "\n",
    "def on_fit_epoch_end(trainer):\n",
    "    # get the results.csv data\n",
    "    results = pd.read_csv(trainer.csv)\n",
    "    # get the current epoch number from the trainer\n",
    "    current_epoch = trainer.epoch\n",
    "    # save epoch's losses\n",
    "    last_row = results.iloc[-1] # Gets results of latest epoch\n",
    "    train_box_losses.append(last_row[\"train/box_loss\"])\n",
    "    train_cls_losses.append(last_row[\"train/cls_loss\"])\n",
    "    train_dfl_losses.append(last_row[\"train/dfl_loss\"])\n",
    "    val_box_losses.append(last_row[\"val/box_loss\"])\n",
    "    val_cls_losses.append(last_row[\"val/cls_loss\"])\n",
    "    val_dfl_losses.append(last_row[\"val/dfl_loss\"])\n",
    "\n",
    "    print(f\"End of epoch {current_epoch + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "error",
     "timestamp": 1758644157247,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "r3yM271IMdS_",
    "outputId": "1c18bf4d-caee-448d-ff50-12732c83f60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 12.0MB/s 0.5s.5s<0.0s.6s\n",
      "WARNING âš ï¸ 'crop_fraction' is deprecated and will be removed in the future.\n",
      "Ultralytics 8.3.206 ðŸš€ Python-3.10.12 torch-2.8.0 CUDA:0 (Orin, 7620MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/root/AUV-2026/ros2_ws/src/vision/model_pipeline/data.yaml, degrees=180, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.3, hsv_v=0.3, imgsz=[480, 640], int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.1, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/root/ultralytics/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.0, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 2.5MB/s 0.3s 0.2s<0.1s\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,018 parameters, 3,012,002 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 12.5MB/s 0.4s.4s<0.0s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "WARNING âš ï¸ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 66.1Â±7.1 MB/s, size: 685.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /root/AUV-2026/ros2_ws/src/vision/model_pipeline/data/augmented/train/labels... 2206 images, 398 backgrounds, 0 corrupt: 25% â”â”â•¸â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2206/8855 110.9it/s 21.3s<60.0s"
     ]
    }
   ],
   "source": [
    "data_yaml_file_absolute_path = os.path.abspath(\"data.yaml\")\n",
    "\n",
    "model = YOLO(model_name) # load a pretrained model.\n",
    "\n",
    "# register fit callback\n",
    "model.add_callback(\"on_fit_epoch_end\", on_fit_epoch_end)\n",
    "\n",
    "# Start the training process.\n",
    "while True:\n",
    "    try:\n",
    "        model.train(\n",
    "            data=data_yaml_file_absolute_path,\n",
    "            epochs=epoch_increments,\n",
    "            imgsz=imgsz,\n",
    "            batch=batch_size,\n",
    "            pretrained=pretrained,\n",
    "            task=\"detect\",\n",
    "            cache=cache,\n",
    "            workers=workers,\n",
    "            hsv_h=hsv_h,\n",
    "            hsv_s=hsv_s,\n",
    "            hsv_v=hsv_v,\n",
    "            translate=translate,\n",
    "            scale=scale,\n",
    "            fliplr=fliplr,\n",
    "            flipud=flipud,\n",
    "            mosaic=mosaic,\n",
    "            copy_paste=copy_paste,\n",
    "            erasing=erasing,\n",
    "            crop_fraction=crop_fraction,\n",
    "            degrees=degrees\n",
    "        )\n",
    "        shutil.copyfile(f\"runs{os_path}detect{os_path}train{os_path}weights{os_path}best.pt\", model_save_filename)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Caught a RuntimeError: {e}.\")\n",
    "        break  # Break out of the loop if an error occurs to prevent infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1758644163384,
     "user": {
      "displayName": "Owen Le Sann",
      "userId": "14841495162809323800"
     },
     "user_tz": 240
    },
    "id": "GIxzu6ijMdS_",
    "outputId": "c56ac240-08ac-4cc0-92c9-83c62e6179f6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3728514452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 1 row, 3 columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Box losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))  # 1 row, 3 columns\n",
    "\n",
    "# Box losses\n",
    "axes[0].plot(train_box_losses, label=\"train losses\")\n",
    "axes[0].plot(val_box_losses, label=\"validation losses\")\n",
    "axes[0].set_title(\"Box Losses Over Time\")\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Classification losses\n",
    "axes[1].plot(train_cls_losses, label=\"train losses\")\n",
    "axes[1].plot(val_cls_losses, label=\"validation losses\")\n",
    "axes[1].set_title(\"Classification Losses Over Time\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Distribution focal losses\n",
    "axes[2].plot(train_dfl_losses, label=\"train losses\")\n",
    "axes[2].plot(val_dfl_losses, label=\"validation losses\")\n",
    "axes[2].set_title(\"Distribution Focal Losses Over Time\")\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"losses_over_time.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSJj5etLMdTA"
   },
   "outputs": [],
   "source": [
    "metrics_val = model.val(data=data_yaml_file_absolute_path, plots=True) # Save metric plots of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONhnqAC3MdTA"
   },
   "outputs": [],
   "source": [
    "metrics_test = model.val(data=data_yaml_file_absolute_path, split=\"test\", plots=True) # Save metric plots of model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
